{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1465876-96e7-4bb1-a8f7-49a98e900fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from filterpy.kalman import KalmanFilter\n",
    "import copy\n",
    "import heapq\n",
    "from scipy.optimize import linear_sum_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20c96aba-c70b-4472-a538-30ec7354ca25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def murty_top_k(cost_matrix, k):\n",
    "    num_rows, num_cols = cost_matrix.shape\n",
    "    base_cost, base_assignment = linear_sum_assignment(cost_matrix)\n",
    "    base_total_cost = cost_matrix[base_cost, base_assignment].sum()\n",
    "\n",
    "    results = [(base_total_cost, list(zip(base_cost, base_assignment)))]\n",
    "    queue = []\n",
    "    heapq.heappush(queue, (base_total_cost, [], base_cost, base_assignment))\n",
    "\n",
    "    seen = set()\n",
    "    seen.add(tuple(base_assignment))\n",
    "\n",
    "    while len(results) < k and queue:\n",
    "        total_cost, fixed, base_rows, base_cols = heapq.heappop(queue)\n",
    "\n",
    "        for i in range(len(base_rows)):\n",
    "            new_cost_matrix = cost_matrix.copy()\n",
    "            for f in fixed:\n",
    "                new_cost_matrix[f[0], :] = np.inf\n",
    "                new_cost_matrix[:, f[1]] = np.inf\n",
    "                new_cost_matrix[f[0], f[1]] = cost_matrix[f[0], f[1]]\n",
    "            new_cost_matrix[base_rows[i], base_cols[i]] = np.inf\n",
    "\n",
    "            try:\n",
    "                new_r, new_c = linear_sum_assignment(new_cost_matrix)\n",
    "                if len(new_r) < num_rows:\n",
    "                    continue\n",
    "                new_assignment = list(zip(new_r, new_c))\n",
    "                key = tuple(new_c)\n",
    "                if key not in seen:\n",
    "                    seen.add(key)\n",
    "                    new_cost = new_cost_matrix[new_r, new_c].sum()\n",
    "                    heapq.heappush(queue, (new_cost, fixed + [(base_rows[i], base_cols[i])], new_r, new_c))\n",
    "                    results.append((new_cost, new_assignment))\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    return [assignment for _, assignment in results[:k]]\n",
    "\n",
    "def create_kalman_filter(init_bbox):\n",
    "    kf = KalmanFilter(dim_x=7, dim_z=4)\n",
    "    kf.F = np.eye(7)\n",
    "    for i in range(4):\n",
    "        kf.F[i, i + 3] = 1.0\n",
    "    kf.H = np.zeros((4, 7))\n",
    "    kf.H[:4, :4] = np.eye(4)\n",
    "    kf.R *= 10.0\n",
    "    kf.P *= 500.0\n",
    "    kf.Q *= 0.01\n",
    "    x, y, w, h = init_bbox\n",
    "    s = w * h\n",
    "    r = w / float(h + 1e-6)\n",
    "    kf.x[:4] = np.array([[x], [y], [s], [r]])\n",
    "    return kf\n",
    "\n",
    "def predict_bbox(kf):\n",
    "    kf.predict()\n",
    "    x, y, s, r = kf.x[:4].flatten()\n",
    "    s = max(s, 1e-3)\n",
    "    r = max(r, 1e-3)\n",
    "    w = np.sqrt(s * r)\n",
    "    h = s / (w + 1e-6)\n",
    "    return [x, y, w, h]\n",
    "def create_kalman_filter(init_bbox):\n",
    "    kf = KalmanFilter(dim_x=7, dim_z=4)\n",
    "    kf.F = np.eye(7)\n",
    "    for i in range(4):\n",
    "        kf.F[i, i + 3] = 1.0\n",
    "    kf.H = np.zeros((4, 7))\n",
    "    kf.H[:4, :4] = np.eye(4)\n",
    "    kf.R *= 10.0\n",
    "    kf.P *= 500.0\n",
    "    kf.Q *= 0.01\n",
    "    x, y, w, h = init_bbox\n",
    "    s = w * h\n",
    "    r = w / float(h + 1e-6)\n",
    "    kf.x[:4] = np.array([[x], [y], [s], [r]])\n",
    "    return kf\n",
    "\n",
    "def predict_bbox(kf):\n",
    "    kf.predict()\n",
    "    x, y, s, r = kf.x[:4].flatten()\n",
    "    s = max(s, 1e-3)\n",
    "    r = max(r, 1e-3)\n",
    "    w = np.sqrt(s * r)\n",
    "    h = s / (w + 1e-6)\n",
    "    return [x, y, w, h]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b187a2-db61-47eb-8df3-ec87d2ab3cc4",
   "metadata": {},
   "source": [
    "MHT Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22cbe21b-7ed1-49fe-823d-7a324d37b792",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealMHT:\n",
    "    def __init__(self, iou_threshold=0.3, prune_k=30, max_hypotheses=5):\n",
    "        self.global_hypotheses = [[]]\n",
    "        self.track_counter = 1\n",
    "        self.iou_threshold = iou_threshold\n",
    "        self.prune_k = prune_k\n",
    "        self.max_hypotheses = max_hypotheses\n",
    "\n",
    "    @staticmethod\n",
    "    def iou(boxA, boxB):\n",
    "        xA = max(boxA[0], boxB[0])\n",
    "        yA = max(boxA[1], boxB[1])\n",
    "        xB = min(boxA[0] + boxA[2], boxB[0] + boxB[2])\n",
    "        yB = min(boxA[1] + boxA[3], boxB[1] + boxB[3])\n",
    "        interArea = max(0, xB - xA) * max(0, yB - yA)\n",
    "        boxAArea = boxA[2] * boxA[3]\n",
    "        boxBArea = boxB[2] * boxB[3]\n",
    "        return interArea / float(boxAArea + boxBArea - interArea + 1e-6)\n",
    "\n",
    "    def match(self, predictions, detections, top_k=3):\n",
    "        if not predictions or not detections:\n",
    "            return [[None] * len(predictions)], list(range(len(detections)))\n",
    "\n",
    "        cost_matrix = np.ones((len(predictions), len(detections)), dtype=np.float32)\n",
    "        for i, p in enumerate(predictions):\n",
    "            for j, d in enumerate(detections):\n",
    "                cost_matrix[i, j] = 1.0 - self.iou(p, d)\n",
    "\n",
    "        assignment_sets = murty_top_k(cost_matrix, k=top_k)\n",
    "\n",
    "\n",
    "        all_matches = []\n",
    "        for assignment in assignment_sets:\n",
    "            match = [None] * len(predictions)\n",
    "            for row, col in assignment:\n",
    "                if row < len(predictions) and col < len(detections):\n",
    "                    if cost_matrix[row, col] < (1.0 - self.iou_threshold):\n",
    "                        match[row] = col\n",
    "            all_matches.append(match)\n",
    "\n",
    "        first_match = all_matches[0] if all_matches else []\n",
    "        matched_dets = set([m for m in first_match if m is not None])\n",
    "        unmatched = list(set(range(len(detections))) - matched_dets)\n",
    "\n",
    "        return all_matches, unmatched\n",
    "\n",
    "    def update(self, detections, frame_idx):\n",
    "        new_global = []\n",
    "        for hypothesis in self.global_hypotheses:\n",
    "            predicted = [predict_bbox(h.kf) for h in hypothesis]\n",
    "            matchings, unmatched_dets = self.match(predicted, detections, top_k=self.max_hypotheses)\n",
    "\n",
    "            for match in matchings[:self.max_hypotheses]:\n",
    "                if len(match) != len(hypothesis):\n",
    "                    continue\n",
    "                new_hypo = []\n",
    "                for i, det_idx in enumerate(match):\n",
    "                    if det_idx is not None:\n",
    "                        if i >= len(hypothesis):\n",
    "                            continue\n",
    "                        parent = hypothesis[i]\n",
    "                        det = detections[det_idx]\n",
    "                        node = HypothesisNode(\n",
    "                            parent, parent.track_id, det, frame_idx,\n",
    "                            kalman_filter=copy.deepcopy(parent.kf)\n",
    "                        )\n",
    "                        parent.children.append(node)\n",
    "                        new_hypo.append(node)\n",
    "                    else:\n",
    "                        if i < len(hypothesis):\n",
    "                            new_hypo.append(hypothesis[i])\n",
    "                new_global.append(new_hypo)\n",
    "\n",
    "            for idx in unmatched_dets:\n",
    "                temp = hypothesis.copy()\n",
    "                node = HypothesisNode(None, self.track_counter, detections[idx], frame_idx)\n",
    "                self.track_counter += 1\n",
    "                temp.append(node)\n",
    "                new_global.append(temp)\n",
    "\n",
    "        new_global.sort(key=lambda hlist: sum(h.score for h in hlist), reverse=True)\n",
    "        self.global_hypotheses = new_global[:self.prune_k]\n",
    "\n",
    "    def get_tracks(self):\n",
    "        tracks_dict = {}\n",
    "    \n",
    "        for hypo in self.global_hypotheses:\n",
    "            for node in hypo:\n",
    "                path = []\n",
    "                cur = node\n",
    "                while cur:\n",
    "                    path.append((cur.frame_idx, cur.track_id, cur.bbox))\n",
    "                    cur = cur.parent\n",
    "                if len(path) >= 1:\n",
    "                    track_id = path[0][1]\n",
    "                    if track_id not in tracks_dict or len(path) > len(tracks_dict[track_id]):\n",
    "                        tracks_dict[track_id] = path[::-1]  # reverse the path\n",
    "    \n",
    "        return list(tracks_dict.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad61e69e-8cfa-4ace-8d5d-480af882a889",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HypothesisNode:\n",
    "    def __init__(self, parent, track_id, bbox, frame_idx, kalman_filter=None):\n",
    "        self.parent = parent\n",
    "        self.track_id = track_id\n",
    "        self.bbox = bbox\n",
    "        self.frame_idx = frame_idx\n",
    "        self.children = []\n",
    "        self.kf = kalman_filter or create_kalman_filter(bbox)\n",
    "        self.kf.update(np.array(bbox[:4]).reshape((4, 1)))\n",
    "        self.score = 0.0 if parent is None else parent.score + self.compute_score()\n",
    "\n",
    "    def compute_score(self):\n",
    "        return 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6654779-3944-440b-831d-9f56c6d42111",
   "metadata": {},
   "source": [
    "Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1a80612-fa21-416b-9420-e7d3557a3d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_lists(folder):\n",
    "    return sorted([os.path.join(folder, f) for f in os.listdir(folder) if f.endswith('.json')])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a4758a-f8d5-4fc3-85d8-8495dd71615e",
   "metadata": {},
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fe59a04-1058-46a6-90b0-fad151f32b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tracking: 100%|█████████████████████████████| 1655/1655 [02:25<00:00, 11.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Final Tracks ===\n",
      "Track ID 8204: 2 frames\n",
      "Track ID 70997: 2 frames\n",
      "Track ID 658348: 2 frames\n",
      "Track ID 1047739: 2 frames\n",
      "Track ID 1664342: 2 frames\n",
      "Track ID 1913186: 1 frames\n",
      "Track ID 1913136: 1 frames\n",
      "Track ID 1913187: 1 frames\n",
      "Track ID 1913086: 1 frames\n",
      "Track ID 1913188: 1 frames\n",
      "Track ID 1913137: 1 frames\n",
      "Track ID 1913189: 1 frames\n",
      "Track ID 1913036: 1 frames\n",
      "Track ID 1913190: 1 frames\n",
      "Track ID 1913138: 1 frames\n",
      "Track ID 1913191: 1 frames\n",
      "Track ID 1913087: 1 frames\n",
      "Track ID 1913192: 1 frames\n",
      "Track ID 1913139: 1 frames\n",
      "Track ID 1913193: 1 frames\n",
      "Track ID 1912986: 1 frames\n",
      "Track ID 1913194: 1 frames\n",
      "Track ID 1913140: 1 frames\n",
      "Track ID 1913195: 1 frames\n",
      "Track ID 1913088: 1 frames\n",
      "Track ID 1913196: 1 frames\n",
      "Track ID 1913141: 1 frames\n",
      "Track ID 1913197: 1 frames\n",
      "Track ID 1913037: 1 frames\n",
      "Track ID 1913198: 1 frames\n",
      "Track ID 1913142: 1 frames\n",
      "Track ID 1913199: 1 frames\n",
      "Track ID 1913089: 1 frames\n",
      "Track ID 1913200: 1 frames\n",
      "Track ID 1913143: 1 frames\n",
      "Track ID 1913201: 1 frames\n",
      "Track ID 1912936: 1 frames\n",
      "Track ID 1913202: 1 frames\n",
      "Track ID 1913144: 1 frames\n",
      "Track ID 1913203: 1 frames\n",
      "Track ID 1913090: 1 frames\n",
      "Track ID 1913204: 1 frames\n",
      "Track ID 1913145: 1 frames\n",
      "Track ID 1913205: 1 frames\n",
      "Track ID 1913038: 1 frames\n",
      "Track ID 1913206: 1 frames\n",
      "Track ID 1913146: 1 frames\n",
      "Track ID 1913207: 1 frames\n",
      "Track ID 1913091: 1 frames\n",
      "Track ID 1913208: 1 frames\n",
      "Track ID 1913147: 1 frames\n",
      "Track ID 1913209: 1 frames\n",
      "Track ID 1912987: 1 frames\n",
      "Track ID 1913210: 1 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "folder = r'C:\\Users\\PC1\\Desktop\\2D\\X-band'\n",
    "json_files = get_file_lists(folder)\n",
    "tracker = RealMHT(iou_threshold=0.1, prune_k=50, max_hypotheses=3)\n",
    "\n",
    "for frame_idx, json_file in enumerate(tqdm(json_files, desc=\"Tracking\", ncols=80)):\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    annotations = data.get('annotations', [])\n",
    "    detections = [[ann['xmin'], ann['ymin'], ann['width'], ann['height']] for ann in annotations]\n",
    "    tracker.update(detections, frame_idx)\n",
    "\n",
    "tracks = tracker.get_tracks()\n",
    "\n",
    "print(\"\\n=== Final Tracks ===\")\n",
    "for track in tracks:\n",
    "    print(f\"Track ID {track[0][1]}: {len(track)} frames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff2f5d7-41e2-4a06-bc3c-458ba9de21db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
